{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot as up\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import mplhep as hep\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from coffea.nanoevents import TreeMakerSchema, BaseSchema, NanoEventsFactory\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "hep.style.use(hep.style.CMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleSelection:\n",
    "    \"\"\"\n",
    "    A class to define and apply particle selection criteria.\n",
    "    \"\"\"\n",
    "    def __init__(self, events):\n",
    "        self.events = events\n",
    "\n",
    "    def make_cut_list(self, elePt_low=5, elePt_high=5, eleEta=2.5, ymass_upper=10):\n",
    "        \"\"\"\n",
    "        Define a list of cuts to be applied to the events.\n",
    "        \"\"\"\n",
    "\n",
    "        cut_fake = (self.events['B_Z_mass'] > -1)\n",
    "        cut_unOrdered_Z = self.events['B_Z_pt1'] > self.events['B_Z_pt2']\n",
    "        cut_unOrdered_J = self.events['B_J_pt1'] > self.events['B_J_pt2']\n",
    "        cut_unOrdered = cut_unOrdered_Z & cut_unOrdered_J\n",
    "\n",
    "        cut_EleTrigger = self.events['B_Z_TriggerPath']\n",
    "        cut_Jsoft = self.events['B_J_soft1'] & self.events['B_J_soft2']\n",
    "        cut_EleTrigEnforce = self.events['B_Z_pt1'] > 27\n",
    "        cut_dilepton_prob = (self.events['B_J_VtxProb'] > 0.01) & (self.events['B_Z_VtxProb'] > 0.01)\n",
    "        cut_FourL_prob = self.events['FourL_VtxProb'] > 0.01\n",
    "\n",
    "        cut_Pt = (self.events['B_Z_pt1'] > 27.0) & (self.events['B_Z_pt2'] > 5.0) & (self.events['B_J_pt1'] > 3.0) & (self.events['B_J_pt2'] > 3.0)\n",
    "        cut_eta = (abs(self.events['B_Z_eta1']) < 2.4) & (abs(self.events['B_Z_eta2']) < 2.4) & (abs(self.events['B_J_eta1']) < 2.5) & (abs(self.events['B_J_eta2']) < 2.5)\n",
    "        cut_detector = cut_Pt & cut_eta\n",
    "\n",
    "        cut_Jmass = (self.events['B_J_mass'] > 3.0) & (self.events['B_J_mass'] < 3.2)\n",
    "        cut_Zmass = (self.events['B_Z_mass'] > 70) & (self.events['B_Z_mass'] < 110)\n",
    "\n",
    "        cut_ZmvaIsoHighpT = self.events['B_Z_mvaIsoWP90_1']\n",
    "        cut_ZmvaIsoLowpT = self.events['B_Z_mvaIsoWP90_2']\n",
    "        cut_ZmvaIsoBoth = (self.events['B_Z_mvaIsoWP90_1']) & (self.events['B_Z_mvaIsoWP90_2'])\n",
    "\n",
    "        cut_FourLmass = (self.events['FourL_mass'] > 112) & (self.events['FourL_mass'] < 162)\n",
    "\n",
    "        return {\n",
    "            \"0\": {\"name\": \"Preselection\", \"mask\": cut_fake},\n",
    "            \"1\": {\"name\": \"UnOrdered pT\", \"mask\": cut_unOrdered},\n",
    "            \"2\": {\"name\": \"Electron Trigger\", \"mask\": cut_EleTrigger},\n",
    "            \"3\": {\"name\": \"Soft Muons\", \"mask\": cut_Jsoft},\n",
    "            \"4\": {\"name\": \"Electron Trigger Enforce\", \"mask\": cut_EleTrigEnforce},\n",
    "            \"5\": {\"name\": \"Dilepton Vtx > 1%\", \"mask\": cut_dilepton_prob, \"var\": [\"B_J_VtxProb\", \"B_Z_VtxProb\"]},\n",
    "            \"6\": {\"name\": \"FourL Vtx > 1%\", \"mask\": cut_FourL_prob, \"var\": [\"FourL_VtxProb\"]},\n",
    "            \"7\": {\"name\": \"Detector acceptance\", \"mask\": cut_detector},\n",
    "            \"8\": {\"name\": \"J mass\", \"mask\": cut_Jmass, \"var\": [\"B_J_mass\"]},\n",
    "            \"9\": {\"name\": \"Z mass\", \"mask\": cut_Zmass, \"var\": [\"B_Z_mass\"]},\n",
    "            \"10\": {\"name\": \"eleID High pT\", \"mask\": cut_ZmvaIsoHighpT, \"var\": [\"B_J_pt1\"]},\n",
    "            \"11\": {\"name\": \"eleID Low pT\", \"mask\": cut_ZmvaIsoLowpT, \"var\": [\"B_J_pt2\"]},\n",
    "            \"12\": {\"name\": \"eleID either\", \"mask\": cut_ZmvaIsoBoth, \"var\": [\"B_J_pt1\", \"B_J_pt2\"]},\n",
    "            \"13\": {\"name\": \"FourL mass\", \"mask\": cut_FourLmass, \"var\": [\"FourL_mass\"]}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plotter:\n",
    "    \"\"\"\n",
    "    A class to handle all plotting functions.\n",
    "    \"\"\"\n",
    "    def __init__(self, savepath):\n",
    "        self.savepath = savepath\n",
    "\n",
    "    def make_hist(self, nbins, xlow, xhigh, values, labels, lines, fileName, xlabel, text_array):\n",
    "        \"\"\"\n",
    "        Create and save a histogram.\n",
    "        \"\"\"\n",
    "        cut_name_at_plot, cut_name_after_plot, n_ev_before, n_eve_after = text_array\n",
    "        unit = 'GeV' if 'eta' not in xlabel else ''\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        for i, value in enumerate(values):\n",
    "            plt.hist(value, bins=nbins, range=(xlow, xhigh), label=labels[i], alpha=0.5)\n",
    "        for line in lines:\n",
    "            plt.axvline(x=line, color='r')\n",
    "\n",
    "        plt.text(0.5, 0.5, f\"Drawn at: {cut_name_at_plot} ({n_ev_before})\", fontsize=12, transform=plt.gca().transAxes)\n",
    "        plt.text(0.5, 0.45, f\"Next cut: {cut_name_after_plot} ({n_eve_after})\", fontsize=12, transform=plt.gca().transAxes)\n",
    "\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(f\"Counts / {(xhigh-xlow)/nbins:.2f} {unit}\")\n",
    "        plt.legend(fontsize=13)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{self.savepath}/{fileName}.png\")\n",
    "        plt.close()\n",
    "\n",
    "    def make_hist2D(self, xvar, yvar, xlabel, ylabel, fileName, text_array):\n",
    "        \"\"\"\n",
    "        Create and save a 2D histogram.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.hist2d(xvar, yvar, bins=(50, 50), range=((-3, 3), (0, 50)))\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{self.savepath}/{fileName}.png\")\n",
    "        plt.close()\n",
    "\n",
    "    # Add other plotting methods here (plot_dilepton_vertexing, plot_dielectron_inv_mass, etc.)\n",
    "\n",
    "class Analysis:\n",
    "    \"\"\"\n",
    "    Main class to perform the analysis.\n",
    "    \"\"\"\n",
    "    def __init__(self, events, savepath):\n",
    "        self.events = events\n",
    "        self.particle_selection = ParticleSelection(events)\n",
    "        self.plotter = Plotter(savepath)\n",
    "\n",
    "\n",
    "    def get_count(self, data):\n",
    "        \"\"\"\n",
    "        Count the number of candidates and events in the given data.\n",
    "        \"\"\"\n",
    "        array = data.B_J_mass\n",
    "        nevents = len(array[ak.num(array, axis=1) > 0])\n",
    "        ncandidates = ak.sum(ak.num(array, axis=1))\n",
    "        return ncandidates, nevents\n",
    "    \n",
    "\n",
    "    def get_summary_of_cuts(self, cut_order):\n",
    "        \"\"\"\n",
    "        Generate a summary of cuts applied to the events.\n",
    "        \"\"\"\n",
    "        key_list = []\n",
    "        ncandidates_list = []\n",
    "        nevents_list = []\n",
    "        aggMask_list = []\n",
    "        var_list = []\n",
    "\n",
    "        agg_mask = self.particle_selection.cut_list[\"0\"][\"mask\"]\n",
    "\n",
    "        for i in cut_order:\n",
    "            mask = self.particle_selection.cut_list[str(i)][\"mask\"]\n",
    "            agg_mask = agg_mask & mask\n",
    "            ncandidates, nevents = self.get_count(self.events[agg_mask])\n",
    "\n",
    "            key_list.append(self.particle_selection.cut_list[str(i)][\"name\"])\n",
    "            ncandidates_list.append(ncandidates)\n",
    "            nevents_list.append(nevents)   \n",
    "            aggMask_list.append(agg_mask)\n",
    "            var_list.append(self.particle_selection.cut_list[str(i)].get(\"var\", None))\n",
    "\n",
    "        summary_dict = {\n",
    "            \"Cut\": key_list, \n",
    "            \"Candidates\": ncandidates_list, \n",
    "            \"Events\": nevents_list, \n",
    "            \"Aggregated mask\": aggMask_list, \n",
    "            \"Var\": var_list\n",
    "        }\n",
    "        \n",
    "        summary_table = pd.DataFrame({key: summary_dict[key] for key in [\"Cut\", \"Candidates\", \"Events\"]})\n",
    "\n",
    "        return summary_dict, summary_table\n",
    "\n",
    "    def get_view_at(self, mycut, summary_dict):\n",
    "        \"\"\"\n",
    "        Get the view of the data at a specific cut.\n",
    "        \"\"\"\n",
    "        mycut_name = self.particle_selection.cut_list[str(mycut)]['name']\n",
    "        cut_index = summary_dict['Cut'].index(mycut_name)\n",
    "        n_events_after_cut = summary_dict['Events'][cut_index]\n",
    "        view_index = cut_index - 1\n",
    "        view_index_name = summary_dict['Cut'][view_index]\n",
    "        view_index_mask = summary_dict['Aggregated mask'][view_index]\n",
    "        n_events_before_cut = summary_dict['Events'][view_index]\n",
    "        cut_of_interest = self.events[view_index_mask]\n",
    "        text_array = [view_index_name, mycut_name, n_events_before_cut, n_events_after_cut]\n",
    "        return cut_of_interest, text_array\n",
    "\n",
    "    def apply_cut_progression(self, cut_progression):\n",
    "        \"\"\"\n",
    "        Apply a series of cuts and create plots at each stage.\n",
    "        \"\"\"\n",
    "        summary_dict, summary_table = self.get_summary_of_cuts(self.events, cut_progression)\n",
    "        print(\"Summary of cuts\")\n",
    "        print(summary_table)\n",
    "        self.show_plots_at_each_cut(summary_dict)\n",
    "        return summary_dict, summary_table\n",
    "\n",
    "    def show_plots_at_each_cut(self, summary_dict):\n",
    "        \"\"\"\n",
    "        Create plots at each cut stage.\n",
    "        \"\"\"\n",
    "        # Implement the logic to create plots at each cut stage\n",
    "        pass\n",
    "\n",
    "    def get_count(self, elePt_low, elePt_high, eleEta, ymass_upper):\n",
    "        \"\"\"\n",
    "        Apply cuts and return the count of events passing all cuts.\n",
    "        \"\"\"\n",
    "        self.particle_selection.cut_list = self.particle_selection.make_cut_list(elePt_low, elePt_high, eleEta, ymass_upper)\n",
    "        eleID_both = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13]\n",
    "        summary_dict, summary_table = self.apply_cut_progression(eleID_both)\n",
    "        count = summary_table[summary_table['Cut'] == 'FourL mass']['Events'].values[0]\n",
    "        return count\n",
    "\n",
    "def get_FOM(events_data, events_mc, savepath_data, savepath_mc, elePt_low, elePt_high, eleEta, ymass_upper):\n",
    "    \"\"\"\n",
    "    Calculate the Figure of Merit.\n",
    "    \"\"\"\n",
    "    analysis_data = Analysis(events_data, savepath_data)\n",
    "    analysis_mc = Analysis(events_mc, savepath_mc)\n",
    "    \n",
    "    nb = analysis_data.get_count(elePt_low, elePt_high, eleEta, ymass_upper)\n",
    "    nEff = analysis_mc.get_count(elePt_low, elePt_high, eleEta, ymass_upper) / 100\n",
    "    FOM = nEff / np.sqrt(nb)\n",
    "    return nEff, nb, FOM\n",
    "\n",
    "def load_config(config_path):\n",
    "    \"\"\"\n",
    "    Load configuration from a YAML file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(config_path, 'r') as config_file:\n",
    "            return yaml.safe_load(config_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Configuration file '{config_path}' not found.\")\n",
    "        sys.exit(1)\n",
    "    except yaml.YAMLError as e:\n",
    "        print(f\"Error parsing YAML configuration file: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def load_events(file_path, schema_class, entry_stop):\n",
    "    \"\"\"\n",
    "    Load events from a ROOT file with error handling.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        events = NanoEventsFactory.from_root(\n",
    "            {file_path: \"ntuple\"}, \n",
    "            schemaclass=schema_class, \n",
    "            entry_stop=entry_stop\n",
    "        ).events()\n",
    "        return events\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading events from '{file_path}': {e}\")\n",
    "        return None\n",
    "\n",
    "def main(config_path='config.yaml', run_data=True, run_mc=True):\n",
    "    # Load configuration\n",
    "    config = load_config(config_path)\n",
    "\n",
    "    events_data = None\n",
    "    events_mc = None\n",
    "\n",
    "    # Load events\n",
    "    if run_data:\n",
    "        events_data = load_events(config['data_path'], BaseSchema, config['entry_stop'])\n",
    "        if events_data is None:\n",
    "            print(\"Failed to load data events. Skipping data analysis.\")\n",
    "            run_data = False\n",
    "\n",
    "    if run_mc:\n",
    "        events_mc = load_events(config['mc_path'], BaseSchema, config['entry_stop'])\n",
    "        if events_mc is None:\n",
    "            print(\"Failed to load MC events. Skipping MC analysis.\")\n",
    "            run_mc = False\n",
    "\n",
    "    if not run_data and not run_mc:\n",
    "        print(\"No valid data or MC events loaded. Exiting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Select columns\n",
    "    if run_data:\n",
    "        events_data = events_data[config['columns']].compute()\n",
    "    if run_mc:\n",
    "        events_mc = events_mc[config['columns']].compute()\n",
    "\n",
    "    # Create DataFrame to store results\n",
    "    df = pd.DataFrame(columns=['elePt_low', 'elePt_high', 'eleEta', 'ymass_upper', 'Efficiency', 'Background', 'FOM'])\n",
    "\n",
    "    # Loop over different cut values\n",
    "    for elePt_low in config['cut_parameters']['elePt_low']:\n",
    "        for elePt_high in config['cut_parameters']['elePt_high']:\n",
    "            for eleEta in config['cut_parameters']['eleEta']:\n",
    "                for ymass_upper in config['cut_parameters']['ymass_upper']:\n",
    "                    savepath_data = f\"{config['savepath_data_base']}el_{elePt_low}_eh_{elePt_high}_eE_{eleEta}_yup_{ymass_upper}\"\n",
    "                    savepath_mc = f\"{config['savepath_mc_base']}el_{elePt_low}_eh_{elePt_high}_eE_{eleEta}_yup_{ymass_upper}\"\n",
    "\n",
    "                    os.makedirs(savepath_data, exist_ok=True)\n",
    "                    os.makedirs(savepath_mc, exist_ok=True)\n",
    "\n",
    "                    eff, nb, FOM = 0, 0, 0\n",
    "                    \n",
    "                    if run_data and run_mc:\n",
    "                        eff, nb, FOM = get_FOM(events_data, events_mc, savepath_data, savepath_mc, elePt_low, elePt_high, eleEta, ymass_upper)\n",
    "                    elif run_data:\n",
    "                        analysis_data = Analysis(events_data, savepath_data)\n",
    "                        nb = analysis_data.get_count(elePt_low, elePt_high, eleEta, ymass_upper)\n",
    "                    elif run_mc:\n",
    "                        analysis_mc = Analysis(events_mc, savepath_mc)\n",
    "                        eff = analysis_mc.get_count(elePt_low, elePt_high, eleEta, ymass_upper) / 100\n",
    "\n",
    "                    df.loc[len(df)] = {'elePt_low': elePt_low, 'elePt_high': elePt_high, 'eleEta': eleEta, 'ymass_upper': ymass_upper, 'Efficiency': eff, 'Background': nb, 'FOM': FOM}\n",
    "                    print(f\"elePt_low: {elePt_low}, elePt_high: {elePt_high}, eleEta: {eleEta}, ymass_upper: {ymass_upper}\")\n",
    "                    print(f\"Efficiency: {eff}\")\n",
    "                    print(f\"Background: {nb}\")\n",
    "                    print(f\"FOM: {FOM}\")\n",
    "                    print(df)\n",
    "                    print(\"\\n\")\n",
    "\n",
    "    print(df)\n",
    "    df.to_csv(config['output_file'], index=False)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser(description=\"Run particle physics analysis on data and/or MC events.\")\n",
    "#     parser.add_argument(\"--config\", default=\"config.yaml\", help=\"Path to the configuration file\")\n",
    "#     parser.add_argument(\"--data\", action=\"store_true\", help=\"Run analysis on data events\")\n",
    "#     parser.add_argument(\"--mc\", action=\"store_true\", help=\"Run analysis on MC events\")\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     if not args.data and not args.mc:\n",
    "#         print(\"Error: You must specify at least one of --data or --mc\")\n",
    "#         sys.exit(1)\n",
    "\n",
    "    # main(config_path=args.config, run_data=args.data, run_mc=args.mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_summary_of_cuts() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 304\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(config_path, run_data, run_mc)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m run_data:\n\u001b[1;32m    303\u001b[0m     analysis_data \u001b[38;5;241m=\u001b[39m Analysis(events_data, savepath_data)\n\u001b[0;32m--> 304\u001b[0m     nb \u001b[38;5;241m=\u001b[39m \u001b[43manalysis_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43melePt_low\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melePt_high\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meleEta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mymass_upper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m run_mc:\n\u001b[1;32m    306\u001b[0m     analysis_mc \u001b[38;5;241m=\u001b[39m Analysis(events_mc, savepath_mc)\n",
      "Cell \u001b[0;32mIn[3], line 206\u001b[0m, in \u001b[0;36mAnalysis.get_count\u001b[0;34m(self, elePt_low, elePt_high, eleEta, ymass_upper)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparticle_selection\u001b[38;5;241m.\u001b[39mcut_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparticle_selection\u001b[38;5;241m.\u001b[39mmake_cut_list(elePt_low, elePt_high, eleEta, ymass_upper)\n\u001b[1;32m    205\u001b[0m eleID_both \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m13\u001b[39m]\n\u001b[0;32m--> 206\u001b[0m summary_dict, summary_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_cut_progression\u001b[49m\u001b[43m(\u001b[49m\u001b[43meleID_both\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m count \u001b[38;5;241m=\u001b[39m summary_table[summary_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCut\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFourL mass\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvents\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m count\n",
      "Cell \u001b[0;32mIn[3], line 187\u001b[0m, in \u001b[0;36mAnalysis.apply_cut_progression\u001b[0;34m(self, cut_progression)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_cut_progression\u001b[39m(\u001b[38;5;28mself\u001b[39m, cut_progression):\n\u001b[1;32m    184\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m    Apply a series of cuts and create plots at each stage.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m     summary_dict, summary_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_summary_of_cuts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcut_progression\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummary of cuts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28mprint\u001b[39m(summary_table)\n",
      "\u001b[0;31mTypeError\u001b[0m: get_summary_of_cuts() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "main(config_path=\"config.yaml\", run_data=True, run_mc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
